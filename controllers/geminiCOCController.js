import { GoogleGenAI } from "@google/genai";

import gameHandlers from "../handlers/gameHandlers.js";
import messageHandlers from "../handlers/messageHandlers.js";

import messageModel from "../models/messageModel.js";
import gameModel from "../models/gameModel.js";

import configService from "../services/config.service.js"

import { io } from "../app.js";
import { buildContextForLLM } from "../tools/COC/buildContextForLLMTool.js";

import rollDiceTool from "../tools/COC/rollDiceTool.js";
import saveCharacterTool from "../tools/COC/saveCharacterTool.js";
import characterImageTool from "../tools/COC/characterImageTool.js";
import triggerSummarizationTool from "../tools/COC/triggerSummarizationTool.js";
import updateCharacterStatsTool from "../tools/COC/updateCharacterStatsTool.js";
import backgroundImageTool from "../tools/COC/backgroundImageTool.js";

const tokenLimit = 10**6;
const triggerLimit = 30000; // 30K
const MAX_TURNS = 5;
const MAX_RETRIES = 5
const INITAIL_DELAY_MS = 1000;
const LLM_NAME = "gemini-2.5-flash";

await configService.loadConfig(true);

const IsCOCSinglePlayOpen = Boolean(configService.get("IsCOCSinglePlayOpen", false));
const COCSinglePlayHasNotCharacterSystemPrompt = configService.get("COCSinglePlayHasNotCharacterSystemPrompt", `ä½ å¿…é ˆåš´æ ¼éµå¾ªä»¥ä¸‹çš„JSONæŒ‡ä»¤å¡Šä¾†æ‰®æ¼”CoC KPçš„è§’è‰²ï¼š
{
  "persona": "å°ˆæ¥­ã€å‹å–„ã€é«˜æ•ˆçš„CoC TRPGå®ˆå¯†äºº(KP)ã€‚",
  "primary_goal": "å¼•å°ç„¡è§’è‰²ç©å®¶å®Œæˆå‰µè§’æµç¨‹ã€‚",
  "decision_flow": {
    "no_character": "åš´æ ¼éµå¾ª: 1.ç†±æƒ…æ­¡è¿ä¸¦è§£é‡‹å‰µè§’é¸é …(éš¨æ©Ÿæ“²éª°/é»æ•¸è³¼è²·)ï¼Œè©¢å•åå¥½ã€‚ 2.è‹¥ç©å®¶é¸'éš¨æ©Ÿæ“²éª°'ä¸¦è¦æ±‚ä»£å‹ï¼Œå¿…é ˆç«‹å³ä¸”å”¯ä¸€åœ°ä½¿ç”¨'rollCharacterStatus'å·¥å…·ï¼Œç¦æ­¢äº‹å‰å°è©±ï¼Œç›´æ¥å‘ˆç¾JSONçµæœå¾Œå†è§£é‡‹ã€‚ 3.è‹¥ç©å®¶é¸'é»æ•¸è³¼è²·'ï¼Œå‘ŠçŸ¥ç¸½é»æ•¸460(ç¯„åœ15-90)ä¸¦å¼•å°åˆ†é…ã€‚ 4.ç©å®¶ç¢ºèªå®Œæˆå¾Œï¼Œå¿…é ˆä½¿ç”¨'saveCharacterStatus'å·¥å…·å„²å­˜ã€‚"
  },
  "rules": {
    "tool_usage": {
      "no_fake_rolls": true,
      "character_creation": "å¿…é ˆä½¿ç”¨ 'rollCharacterStatus'",
      "ingame_checks": "å¿…é ˆä½¿ç”¨ 'rollSingleDice'"
    }
  },
  "knowledge_base": {
    "attributes": {
      "STR": {"roll": "(3d6)*5", "buy_range": "15-90"},
      "CON": {"roll": "(3d6)*5", "buy_range": "15-90"},
      "SIZ": {"roll": "(2d6+6)*5", "buy_range": "15-90"},
      "DEX": {"roll": "(3d6)*5", "buy_range": "15-90"},
      "APP": {"roll": "(3d6)*5", "buy_range": "15-90"},
      "INT": {"roll": "(2d6+6)*5", "buy_range": "15-90"},
      "POW": {"roll": "(3d6)*5", "buy_range": "15-90"},
      "EDU": {"roll": "(2d6+6)*5", "buy_range": "15-90"},
      "LUCK": {"roll": "(3d6)*5", "buy_range": "N/A"}
    },
    "derived_stats": {
      "HP": "floor((SIZ+CON)/10)",
      "MP": "floor(POW/5)",
      "SAN": "POW"
    },
    "skill_points": {
      "occupation": "ä¾è·æ¥­å…¬å¼è¨ˆç®— (ä¾‹: ä½œå®¶=EDU*4, é‹å‹•å“¡=EDU*2+STR*2, æ ¹æ“šè·æ¥­æ‰€é•·ç‚ºEDU*2+XXX*2)",
      "interest": "INT*2"
    }
  }}`);
const COCSinglePlayHasCharacterSystemPrompt = configService.get("COCSinglePlayHasCharacterSystemPrompt", `{
  "profile": {
    "identity": "å°ˆæ¥­ã€å‹å–„ä¸”é«˜æ•ˆçš„ã€Šå…‹è˜‡é­¯çš„å‘¼å–šã€‹TRPG å®ˆå¯†äºº (KP)ã€‚",
    "primary_task": "å¼•å°ç©å®¶å®Œæˆå……æ»¿æœªçŸ¥ã€ææ€–å’Œç˜‹ç‹‚çš„å†’éšªï¼Œä¸¦æ ¹æ“šä»–å€‘çš„è¡Œå‹•æ¨å‹•åŠ‡æƒ…ã€‚",
    "communication_style": "æ¸…æ™°ã€ç°¡æ½”ï¼Œå–„æ–¼ç”¨å´é¢æå¯«å’Œç´°ç¯€ç‡Ÿé€ æ‡¸ç–‘ææ€–çš„æ°£æ°›ã€‚åš´æ ¼éµå®ˆã€Šå…‹è˜‡é­¯çš„å‘¼å–šã€‹çš„è¦å‰‡ï¼Œç‰¹åˆ¥æ˜¯ä½•æ™‚æ“²éª°æ–¹é¢ã€‚"
    "response_requirements": "åœ¨ä½ çš„æœ€çµ‚å›æ‡‰ä¸­ï¼Œä¸å¾—åŒ…å«ä»»ä½•å…§éƒ¨çš„æ€è€ƒã€æ¨ç†æˆ–ã€THOUGHTã€å€å¡Šã€‚"
  },
  "core_gameplay_loop": [
    "1. è†è½èˆ‡æ¾„æ¸…ï¼šä»”ç´°è†è½ç©å®¶çš„è¡Œå‹•æè¿°ã€‚è‹¥æè¿°æ¨¡ç³Šï¼ˆå¦‚ã€æˆ‘ç”¨å·¥å…·ã€ï¼‰ï¼Œå¿…é ˆè¿½å•ç´°ç¯€ï¼ˆã€ä»€éº¼å·¥å…·ï¼Ÿã€ï¼‰ä»¥ç¢ºä¿è¡Œå‹•åˆç†å¯è¡Œã€‚",
    "2. åˆ¤æ–·æª¢å®šï¼šæ ¹æ“šç©å®¶è¡Œå‹•å’Œè¦å‰‡ï¼Œåˆ¤æ–·æ˜¯å¦éœ€è¦èƒ½åŠ›æª¢å®šã€‚è‹¥è¡Œå‹•æ¥µå…¶ç°¡å–®æˆ–å¿…ç„¶æˆåŠŸ/å¤±æ•—ï¼Œå‰‡ç›´æ¥é€²è¡Œæ•˜äº‹ã€‚",
    "3. ç™¼èµ·æª¢å®šæˆ–æ•˜äº‹ï¼šè‹¥éœ€æª¢å®šï¼Œå¿…é ˆç«‹å³å‘¼å« 'rollSingleDice' å·¥å…·ï¼Œä¸¦åœ¨ 'reason' åƒæ•¸ä¸­æè¿°æª¢å®šåŸå› ï¼ˆæ ¼å¼ï¼š'æª¢å®šåç¨± (ç›®æ¨™å€¼%): åŸå› 'ï¼‰ã€‚è‹¥ç„¡éœ€æª¢å®šï¼Œå‰‡ç›´æ¥é€²è¡Œæ•˜äº‹ã€‚"
  ],
  "rules": {
    "tool_usage": {
      "rollSingleDice": "é€™æ˜¯ä½ å”¯ä¸€è¢«å…è¨±çš„æ“²éª°æ–¹å¼ï¼Œç”¨ä»¥ç¢ºä¿å…¬å¹³ã€‚æ‰€æœ‰NPCæˆ–ç’°å¢ƒéš¨æ©Ÿäº‹ä»¶å‡é ˆä½¿ç”¨æ­¤å·¥å…·ã€‚",
      "secret_rolls": "å¦‚éœ€é€²è¡Œæš—éª°ï¼ˆå¦‚å¿ƒç†å­¸ï¼‰ï¼Œåœ¨å‘¼å« 'rollSingleDice' å·¥å…·æ™‚ï¼Œåœ¨åƒæ•¸ä¸­åŠ å…¥ 'secret: true'ã€‚",
      "generateBackgroundImage": "ç•¶è§’è‰²å»åˆ°å¦ä¸€å€‹å ´æ‰€çš„æ™‚å€™ï¼Œä½ **å¿…é ˆç«‹å³ä½¿ç”¨**ä¾†ç”Ÿæˆæ–°çš„å ´æ™¯ã€‚å¢åŠ ç©å®¶çš„æ²‰å…¥æ„Ÿã€‚",
    },
    "system_input_interpretation": {
      "response_structure": {
        "step_1_header": "å¿…é ˆåœ¨å›è¦†çš„ã€ç¬¬ä¸€è¡Œã€‘ç”Ÿæˆã€Œçµæœæ¨™é ­ã€ï¼Œæ ¼å¼ç‚ºï¼š'ã€<èƒ½åŠ›åç¨±>æª¢å®šï¼š<æ“²éª°çµæœ>/<ç›®æ¨™å€¼> -> <æˆåŠŸ/å¤±æ•—/å¤§æˆåŠŸ/å¤§å¤±æ•—>ã€‘'ã€‚ç¯„ä¾‹ï¼šã€åµæŸ¥æª¢å®šï¼š75/80 -> æˆåŠŸã€‘ã€‚",
        "step_2_narrative": "åœ¨æ¨™é ­å¾Œã€æ›è¡Œã€‘ï¼Œé–‹å§‹æ’°å¯«è©³ç´°çš„åŠ‡æƒ…æè¿°ã€‚æ•˜äº‹ä¸­æ‡‰é¿å…é‡è¤‡æåŠæˆåŠŸ/å¤±æ•—æˆ–å…·é«”æ•¸å­—ï¼Œè¦å°‡çµæœå®Œå…¨èå…¥æ•…äº‹ã€‚"
      },
      "interpretation_details": {
        "success": "ç”Ÿå‹•åœ°æè¿°æˆåŠŸçš„å ´æ™¯ã€‚",
        "failure": "æè¿°å¤±æ•—çš„å ´æ™¯å’Œå¾Œæœã€‚",
        "critical_success": "æè¿°å¤§æˆåŠŸï¼Œä¸¦æä¾›æ„æƒ³ä¸åˆ°çš„æ­£é¢æ•ˆæœã€‚",
        "critical_fumble": "æè¿°å¤§å¤±æ•—ï¼Œä¸¦è§¸ç™¼æ›´ç³Ÿç³•çš„è² é¢å¾Œæœã€‚"
      }
    }
  },
  "narrative_style_guide": {
    "atmosphere": "æ ¸å¿ƒæ˜¯æœªçŸ¥ææ€–ã€‚çµ•å°ç¦æ­¢ç›´å‘¼ç¥è©±ç”Ÿç‰©æˆ–èˆŠæ—¥æ”¯é…è€…ä¹‹åã€‚ä½¿ç”¨ç’°å¢ƒæš—ç¤ºã€æ„Ÿå®˜ç´°ç¯€ã€ç•°å¸¸ç¾è±¡ç‡Ÿé€ æ°›åœï¼Œå¼·èª¿ç©å®¶åœ¨æœªçŸ¥é¢å‰çš„æ¸ºå°èˆ‡ç„¡åŠ›ã€‚",
    "character_control": "åš´å®ˆç©å®¶ä»£ç†æ¬Šï¼Œçµ•ä¸æ›¿ç©å®¶è§’è‰²ï¼ˆPCï¼‰åšä»»ä½•æ±ºå®šã€‚ä½ æ§åˆ¶æ‰€æœ‰éç©å®¶è§’è‰²ï¼ˆNPCï¼‰ï¼Œä¸¦ä½¿å…¶è¡Œå‹•ç¬¦åˆå…¶æ€§æ ¼å‹•æ©Ÿã€‚"
  }}`);
const ThankForTesting = configService.get("ThankForTesting", "Testing time has been ended. Thank you for your testingğŸ˜†")

const retryMessages = {
  "0": "Brewing a little more coffee... Gemini is giving it another shot! â˜•",
  "1": "Hmm, that didn't quite work. Gemini is trying a different angle! ğŸ¤”",
  "2": "Whoops, a little turbulence! Rerouting the connection now... âœˆï¸",
  "3": "Just a moment! Gemini is tightening some digital screws... ğŸ”©",
  "4": "It looks like our Gemini KP is facing some stubborn network issues. \nWe've made several attempts to resolve it automatically. \nCould you please try again shortly?ğŸ™‡â€â™€ï¸ \nOur team has been alerted if the issue persists."
}

const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API });

const startPrompt = `Start, please introduce yourself and what the game is?`;

// const systemPrompt = (userLanguage, haveCharacter) => {
//   if (haveCharacter)
//     return `
//                     `;
//   return ` ä½ å¿…é ˆåš´æ ¼éµå¾ªä»¥ä¸‹çš„JSONæŒ‡ä»¤å¡Šä¾†æ‰®æ¼”CoC KPçš„è§’è‰²ï¼š
// {
//   "persona": "å°ˆæ¥­ã€å‹å–„ã€é«˜æ•ˆçš„CoC TRPGå®ˆå¯†äºº(KP)ã€‚",
//   "primary_goal": "å¼•å°ç„¡è§’è‰²ç©å®¶å®Œæˆå‰µè§’æµç¨‹ã€‚",
//   "decision_flow": {
//     "no_character": "åš´æ ¼éµå¾ª: 1.ç†±æƒ…æ­¡è¿ä¸¦è§£é‡‹å‰µè§’é¸é …(éš¨æ©Ÿæ“²éª°/é»æ•¸è³¼è²·)ï¼Œè©¢å•åå¥½ã€‚ 2.è‹¥ç©å®¶é¸'éš¨æ©Ÿæ“²éª°'ä¸¦è¦æ±‚ä»£å‹ï¼Œå¿…é ˆç«‹å³ä¸”å”¯ä¸€åœ°ä½¿ç”¨'rollCharacterStatus'å·¥å…·ï¼Œç¦æ­¢äº‹å‰å°è©±ï¼Œç›´æ¥å‘ˆç¾JSONçµæœå¾Œå†è§£é‡‹ã€‚ 3.è‹¥ç©å®¶é¸'é»æ•¸è³¼è²·'ï¼Œå‘ŠçŸ¥ç¸½é»æ•¸460(ç¯„åœ15-90)ä¸¦å¼•å°åˆ†é…ã€‚ 4.ç©å®¶ç¢ºèªå®Œæˆå¾Œï¼Œå¿…é ˆä½¿ç”¨'saveCharacterStatus'å·¥å…·å„²å­˜ã€‚"
//   },
//   "rules": {
//     "tool_usage": {
//       "no_fake_rolls": true,
//       "character_creation": "å¿…é ˆä½¿ç”¨ 'rollCharacterStatus'",
//       "ingame_checks": "å¿…é ˆä½¿ç”¨ 'rollSingleDice'"
//     }
//   },
//   "knowledge_base": {
//     "attributes": {
//       "STR": {"roll": "(3d6)*5", "buy_range": "15-90"},
//       "CON": {"roll": "(3d6)*5", "buy_range": "15-90"},
//       "SIZ": {"roll": "(2d6+6)*5", "buy_range": "15-90"},
//       "DEX": {"roll": "(3d6)*5", "buy_range": "15-90"},
//       "APP": {"roll": "(3d6)*5", "buy_range": "15-90"},
//       "INT": {"roll": "(2d6+6)*5", "buy_range": "15-90"},
//       "POW": {"roll": "(3d6)*5", "buy_range": "15-90"},
//       "EDU": {"roll": "(2d6+6)*5", "buy_range": "15-90"},
//       "LUCK": {"roll": "(3d6)*5", "buy_range": "N/A"}
//     },
//     "derived_stats": {
//       "HP": "floor((SIZ+CON)/10)",
//       "MP": "floor(POW/5)",
//       "SAN": "POW"
//     },
//     "skill_points": {
//       "occupation": "ä¾è·æ¥­å…¬å¼è¨ˆç®— (ä¾‹: ä½œå®¶=EDU*4, é‹å‹•å“¡=EDU*2+STR*2, æ ¹æ“šè·æ¥­æ‰€é•·ç‚ºEDU*2+XXX*2)",
//       "interest": "INT*2"
//     }
//   }
// }
// `;
// };

const handlerNewCOCChat = async (socket) => {
  console.log("gemini start to run ğŸ¤–")
  const userId = socket.user._id;
  const userLanguage = socket.user.language;

  if (!(IsCOCSinglePlayOpen || Boolean(socket.user.isAdmin))) {
    socket.emit("game:created", {
      message: ThankForTesting,
      gameId: "1"
    })
    return;
  }

  try{
    const result = await ai.models.generateContent({
        model: LLM_NAME,
        contents: startPrompt,
        config: { 
          systemInstruction: COCSinglePlayHasNotCharacterSystemPrompt + `please response with ${userLanguage}`,
         }
    })

    const modelResponseText = result.text;

    console.log("Model Response Text: ", modelResponseText);

    const { promptTokenCount, candidatesTokenCount, totalTokenCount, thoughtsTokenCount } = result.usageMetadata;

    console.log(`input_tokens: ${promptTokenCount} | output_tokens: ${candidatesTokenCount} | thoughtsTokenCount: ${thoughtsTokenCount} | totak_tokens: ${totalTokenCount}`)

    const game = await gameHandlers.createGame(userId);
    const gameId = game._id;
    
    await messageModel.create({
      gameId,
      message_type: "model_text_response",
      role: "model",
      content: modelResponseText,
      usage: {
        inputTokens: promptTokenCount,
        outputTokens: candidatesTokenCount + thoughtsTokenCount,
      }
    })

    await gameModel.findByIdAndUpdate(gameId, {
      $inc: {
        "tokenUsage.inputTokens": promptTokenCount,
        "tokenUsage.outputTokens": candidatesTokenCount + thoughtsTokenCount,
        "tokenUsage.totalTokens": totalTokenCount,
      }
    })

    socket.emit("game:created", {
      message: modelResponseText,
      gameId: gameId
    })
    
    socket.join(gameId);
    console.log(`player ${socket.user.username} join game room ${gameId}`)

  } catch (error) {
    console.error("Error âš ï¸ in handlerNewCOCChat: fail to call Gemini API: ", error);
    socket.emit("game:createError", {
      message: "fail to get response from AI, please try later."
    })
  }
}

const handlerUserMessageCOCChat = async (data, user, role) => {
  console.log("Gemini start reading")
  const { gameId, message } = data;
  const userId = user._id;
  const language = user.language;
  if (!message || message.length === 0) {
    io.to(gameId).emit("message:error", { error: { message: "empty input" } })
    return;
  }

  console.log(`!(IsCOCSinglePlayOpen || Boolean(user.isAdmin)): !(${IsCOCSinglePlayOpen} || ${Boolean(user.isAdmin)}) ==> ${!(IsCOCSinglePlayOpen || Boolean(user.isAdmin))}`)

  if (!(IsCOCSinglePlayOpen || Boolean(user.isAdmin))) {
    io.to(gameId).emit("message:received", { message: ThankForTesting, role: "system" });
    return;
  }

  // for testing
  // console.log("gemini got message from user with gameId", gameId);
  // io.to(gameId).emit("message:received", { message: "got your message "+ message, role: "model" });
  // return;
  
  const { messages, character, game } = await gameHandlers.getGameById(
    gameId,
    userId
  );

  const userNewMessage = await messageModel.create({
    gameId,
    message_type: "user_prompt",
    role: "user",
    content: message,
  })

  const newMessgesId = [userNewMessage._id]; // go to delete if gemini fail

  const hasCharacter = character ? true : false;

  try {
    const availableTools = {
      rollSingleDice: rollDiceTool.rollSingleDice,
      // updateGameState: saveGameStateTool.updateGameState
      generateCharacterImage: characterImageTool.generateCharacterImage
    };

    let functionDeclarations = [
      rollDiceTool.rollSingleDiceDeclaration,
      // saveGameStateTool.updateGameStateDeclaration,
      characterImageTool.generateCharacterImageDeclaration,
    ];

    console.log("hasCharacter: ", hasCharacter);

    if (!hasCharacter) {
      availableTools["saveCharacterStatus"] = saveCharacterTool.saveCharacterStatus;
      availableTools["rollCharacterStatus"] = rollDiceTool.rollCharacterStatus;
      functionDeclarations = [
        ...functionDeclarations,
        ...[
          rollDiceTool.rollCharacterStatusDeclaration,
          saveCharacterTool.saveCharacterStatusDeclaration,
        ],
      ];
    } else {
      availableTools["updateCharacterStats"] = updateCharacterStatsTool.updateCharacterStats;
      availableTools["generateBackgroundImage"] = backgroundImageTool.generateBackgroundImage;
      functionDeclarations = [
        ...functionDeclarations,
        ...[
          updateCharacterStatsTool.updateCharacterStatsDeclaration,
          backgroundImageTool.generateBackgroundImageDeclaration,
        ],
      ];
    }
    // count token-------------------------------------------------
    const historyContents = buildContextForLLM(game, character, messages);

    const latestUserPrompt = { role: "user", parts: [{ text: message }] };

    const contents = [...historyContents, latestUserPrompt]

    // console.log("contents is: ", contents)

    const countTokensResponse = await ai.models.countTokens({
      model: LLM_NAME,
      contents: contents,
    })

    const totalTokens = countTokensResponse.totalTokens;

    console.log("The total token is: ", totalTokens);
    // --------------------------------------------------------------

    if ( totalTokens > tokenLimit ) {
      throw new Error("Content window is too large, aborting request.");
    }

    if (totalTokens > triggerLimit) {
      await triggerSummarizationTool.triggerSummarization(game, messages)
    }

    // retry system
    let lastError = null;
    for (let attempt = 0; attempt < MAX_RETRIES; attempt++){
      console.log(`Gemini API ${attempt + 1} try`);
      try {
        // Gemini agent system
        for (let i = 0; i < MAX_TURNS; i++) {
          console.log("start checking model used function call or not.")
          const result = await ai.models.generateContent({
            model: LLM_NAME,
            contents: contents,
            config: { 
              tools: [{ functionDeclarations }],
              systemInstruction: hasCharacter ? 
              COCSinglePlayHasCharacterSystemPrompt + `please response with ${language}` : 
              COCSinglePlayHasNotCharacterSystemPrompt + `please response with ${language}`,
            }
          })

          const { promptTokenCount, candidatesTokenCount, totalTokenCount, thoughtsTokenCount } = result.usageMetadata;

          const outputTokens = (candidatesTokenCount || 0) + (thoughtsTokenCount || 0);

          console.log(`input_tokens: ${promptTokenCount} | output_tokens: ${outputTokens} | total_tokens: ${totalTokenCount}`);

          // await gameHandlers.addUsedTokenGameById(gameId, usedToken);

          await gameModel.findByIdAndUpdate(gameId, {
            $inc: {
              "tokenUsage.inputTokens": promptTokenCount || 0,
              "tokenUsage.outputTokens": outputTokens,
              "tokenUsage.totalTokens": totalTokenCount || 0,
            }
          })

          if (result.functionCalls && result.functionCalls.length > 0){
            const functionCall = result.functionCalls[0];

            console.log(`functionCall is: ${JSON.stringify(functionCall)}`)

            const { name, args } = functionCall;

            const modelFunctionCallMessage = await messageModel.create({
              gameId,
              message_type: "model_function_call",
              role: "model",
              content: `Gemini use ${name} function`,
              function_call: functionCall,
              usage: {
                inputTokens: promptTokenCount,
                outputTokens: outputTokens,
              }
            })

            io.to(gameId).emit("systemMessage:received", {message: `Gemini use ${name} function`, followingMessage: "Gemini is waiting the resultâ˜•"})

            newMessgesId.push(modelFunctionCallMessage._id)


            if (!availableTools[name]) {
              throw new Error("unknown function call: ", name);
            }

            // console.log("model wants to call a function: ", name);
            // console.log("white arguments: ", args);

            args["userId"] = userId;
            args["gameId"] = gameId;
            args["game"] = game;
            args["characterId"] = character?._id || null;

            const { toolResult, functionMessage } = await availableTools[name](args);

            console.log("function execution result: ", toolResult);

            contents.push({
              role: "model",
              parts: [{
                functionCall: functionCall
              }]
            })

            contents.push({
              role: "user",
              parts: [{
                functionResponse: {
                  name,
                  response: toolResult,
                }
              }]
            })

            const functionCallResultMessage = await messageModel.create({
              gameId,
              message_type: "tool_function_result",
              role: "system",
              content: functionMessage,
              function_result: {
                name,
                result: toolResult
              }
            })

            newMessgesId.push(functionCallResultMessage._id)

          } else {
            console.log("model don't have use function call.")
            console.log(`model result:\n${JSON.stringify(result, null, 2)}`)
            const modelResponseText = result.text;
            console.log("Model Resonse Text: ", modelResponseText);

            if (!modelResponseText || modelResponseText.trim() === "" ) {
              console.error("Error âš ï¸: Gemini returned an empty response.");
              throw new Error("Gemini returned an empty response");
            }

            console.log("Gemini Response Text is valid, saving messages to DB...")

            const modelResponseMessage = await messageModel.create({
              gameId,
              message_type: "model_text_response",
              role: "model",
              content: modelResponseText,
              usage: {
                inputTokens: promptTokenCount,
                outputTokens: outputTokens,
              }
            })

            newMessgesId.push(modelResponseMessage._id)

            io.to(gameId).emit("message:received", { message: modelResponseText, role: "model" });
            return;
          }
        }
      } catch (error) {
        lastError = error;
        if (error.message.includes("500") || error.message.includes("503")) {
          if (attempt === MAX_RETRIES - 1) {
            console.error("Error âš ï¸: Gemini API meet max retries. Stop retry");
            io.to(gameId).emit("message:error", { error: retryMessages[`${attempt}`] })
            throw new Error ("Error âš ï¸: Gemini fail to use function callğŸ¤¦")
          }
          io.to(gameId).emit("systemMessage:received", { message: retryMessages[`${attempt}`], keepLoading: true })

          const delay = INITAIL_DELAY_MS * Math.pow(2, attempt);
          const jitter = Math.random() * 1000;
          const waitTime = delay + jitter;

          console.log(`Gemini API Error in ${attempt + 1} try: Error âš ï¸: ${error.message}`);
          console.log(`Retry ğŸ¤¦ at ${(waitTime / 1000).toFixed(2)} second later`);

          await new Promise(resolve => setTimeout(resolve, waitTime));
        } else {
          console.log(`Non retry Error âš ï¸: ${error.message}`);
          throw error
        }
      }
    }
  } catch (error) {
    console.error("Error âš ï¸: fail to call Gemini API: ", error);
    io.to(gameId).emit("message:error", { error: "Error âš ï¸: fail to call Gemini API \n If you are trying to ask Gemini to roll a dice, please type '/roll XdY', which X is the number of dice and Y is the number of faces of the dice, to roll dice.", originalMessage: message })
    newMessgesId.forEach((messageId) => messageHandlers.deleteMessage(messageId));
  }
}

export default {
  handlerNewCOCChat,
  handlerUserMessageCOCChat,
};
